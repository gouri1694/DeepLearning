{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinearRegression_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMQO-lpC6lgI",
        "outputId": "d416f633-2e9e-4037-dc91-bce9309cae6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.8.0-cp37-cp37m-manylinux2010_x86_64.whl (497.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 497.5 MB 18 kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.14.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (13.0.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.24.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.8.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 68.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.5.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.10.0.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.44.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.21.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow-gpu) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow-gpu) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-gpu\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "D2IliGyI62B0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_fyxUHb7GuH",
        "outputId": "79e6334e-9e05-4fc1-882e-d96baed400c7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "LLvV2K-o7KAp"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the dataset\n",
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "X = dataset.iloc[:, 3:12]\n",
        "y = dataset.iloc[:, 12]"
      ],
      "metadata": {
        "id": "gHRHobkK7Sxn"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QXbFp-XaVOnN",
        "outputId": "3b3c14e6-1b3a-49ec-eb1a-fe347c7e3110"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
              "0             619    France  Female   42       2       0.00              1   \n",
              "1             608     Spain  Female   41       1   83807.86              1   \n",
              "2             502    France  Female   42       8  159660.80              3   \n",
              "3             699    France  Female   39       1       0.00              2   \n",
              "4             850     Spain  Female   43       2  125510.82              1   \n",
              "...           ...       ...     ...  ...     ...        ...            ...   \n",
              "9995          771    France    Male   39       5       0.00              2   \n",
              "9996          516    France    Male   35      10   57369.61              1   \n",
              "9997          709    France  Female   36       7       0.00              1   \n",
              "9998          772   Germany    Male   42       3   75075.31              2   \n",
              "9999          792    France  Female   28       4  130142.79              1   \n",
              "\n",
              "      HasCrCard  IsActiveMember  \n",
              "0             1               1  \n",
              "1             0               1  \n",
              "2             1               0  \n",
              "3             0               0  \n",
              "4             1               1  \n",
              "...         ...             ...  \n",
              "9995          1               0  \n",
              "9996          1               1  \n",
              "9997          0               1  \n",
              "9998          1               0  \n",
              "9999          1               0  \n",
              "\n",
              "[10000 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b006c472-531a-4e72-b80f-33b5c75a0fb6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>771</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>516</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>709</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>772</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>792</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b006c472-531a-4e72-b80f-33b5c75a0fb6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b006c472-531a-4e72-b80f-33b5c75a0fb6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b006c472-531a-4e72-b80f-33b5c75a0fb6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_4FyJQuVRDV",
        "outputId": "7856fd74-9bea-4291-bfcc-38ccf77bd511"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       101348.88\n",
              "1       112542.58\n",
              "2       113931.57\n",
              "3        93826.63\n",
              "4        79084.10\n",
              "          ...    \n",
              "9995     96270.64\n",
              "9996    101699.77\n",
              "9997     42085.58\n",
              "9998     92888.52\n",
              "9999     38190.78\n",
              "Name: EstimatedSalary, Length: 10000, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create dummy variables\n",
        "geography=pd.get_dummies(X[\"Geography\"],drop_first=True)\n",
        "gender=pd.get_dummies(X['Gender'],drop_first=True)"
      ],
      "metadata": {
        "id": "T2yS0VL67Ufn"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Concatenate the Data Frames\n",
        "\n",
        "X=pd.concat([X,geography,gender],axis=1)\n",
        "\n",
        "## Drop Unnecessary columns\n",
        "X=X.drop(['Geography','Gender'],axis=1)\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
      ],
      "metadata": {
        "id": "Co2rxaFR7Wgo"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYWXFe_ZYtAx",
        "outputId": "a757e08d-afea-4e81-eaf9-112d1bceb6a0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
              " 7389          667   34       5       0.00              2          1   \n",
              " 9275          427   42       1   75681.52              1          1   \n",
              " 2995          535   29       2  112367.34              1          1   \n",
              " 5316          654   40       5  105683.63              1          1   \n",
              " 356           850   57       8  126776.30              2          1   \n",
              " ...           ...  ...     ...        ...            ...        ...   \n",
              " 9225          594   32       4  120074.97              2          1   \n",
              " 4859          794   22       4  114440.24              1          1   \n",
              " 3264          738   35       5  161274.05              2          1   \n",
              " 9845          590   38       9       0.00              2          1   \n",
              " 2732          623   48       1  108076.33              1          1   \n",
              " \n",
              "       IsActiveMember  Germany  Spain  Male  \n",
              " 7389               0        0      1     0  \n",
              " 9275               1        1      0     1  \n",
              " 2995               0        0      0     0  \n",
              " 5316               0        0      1     1  \n",
              " 356                1        0      1     0  \n",
              " ...              ...      ...    ...   ...  \n",
              " 9225               1        1      0     0  \n",
              " 4859               1        0      1     0  \n",
              " 3264               0        0      0     1  \n",
              " 9845               1        0      1     0  \n",
              " 2732               0        1      0     0  \n",
              " \n",
              " [8000 rows x 10 columns],\n",
              "       CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
              " 9394          597   35       8  131101.04              1          1   \n",
              " 898           523   40       2  102967.41              1          1   \n",
              " 2398          706   42       8   95386.82              1          1   \n",
              " 5906          788   32       4  112079.58              1          0   \n",
              " 2343          706   38       5  163034.82              2          1   \n",
              " ...           ...  ...     ...        ...            ...        ...   \n",
              " 1037          625   24       1       0.00              2          1   \n",
              " 2899          586   35       7       0.00              2          1   \n",
              " 9549          578   36       1  157267.95              2          1   \n",
              " 2740          650   34       4  142393.11              1          1   \n",
              " 6690          573   30       8  127406.50              1          1   \n",
              " \n",
              "       IsActiveMember  Germany  Spain  Male  \n",
              " 9394               1        1      0     0  \n",
              " 898                0        0      0     0  \n",
              " 2398               1        0      1     0  \n",
              " 5906               0        0      0     1  \n",
              " 2343               1        1      0     1  \n",
              " ...              ...      ...    ...   ...  \n",
              " 1037               1        0      0     0  \n",
              " 2899               0        0      0     0  \n",
              " 9549               0        0      1     1  \n",
              " 2740               1        1      0     1  \n",
              " 6690               0        1      0     1  \n",
              " \n",
              " [2000 rows x 10 columns],\n",
              " 7389    163830.64\n",
              " 9275     57098.00\n",
              " 2995    185630.76\n",
              " 5316    173617.09\n",
              " 356     132298.49\n",
              "           ...    \n",
              " 9225    162961.79\n",
              " 4859    107753.07\n",
              " 3264    181429.87\n",
              " 9845    148750.16\n",
              " 2732    118855.26\n",
              " Name: EstimatedSalary, Length: 8000, dtype: float64,\n",
              " 9394    192852.67\n",
              " 898     128702.10\n",
              " 2398     75732.25\n",
              " 5906     89368.59\n",
              " 2343    135662.17\n",
              "           ...    \n",
              " 1037    180969.55\n",
              " 2899     70760.69\n",
              " 9549    141533.19\n",
              " 2740     11276.48\n",
              " 6690    192950.60\n",
              " Name: EstimatedSalary, Length: 2000, dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n"
      ],
      "metadata": {
        "id": "GNZrZXy37ZLs"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6o0xBo_Y8mU",
        "outputId": "8ac82684-de12-4ef2-c468-d93b3ed4bec4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.16958176, -0.46460796,  0.00666099, ..., -0.5698444 ,\n",
              "         1.74309049, -1.09168714],\n",
              "       [-2.30455945,  0.30102557, -1.37744033, ...,  1.75486502,\n",
              "        -0.57369368,  0.91601335],\n",
              "       [-1.19119591, -0.94312892, -1.031415  , ..., -0.5698444 ,\n",
              "        -0.57369368, -1.09168714],\n",
              "       ...,\n",
              "       [ 0.9015152 , -0.36890377,  0.00666099, ..., -0.5698444 ,\n",
              "        -0.57369368,  0.91601335],\n",
              "       [-0.62420521, -0.08179119,  1.39076231, ..., -0.5698444 ,\n",
              "         1.74309049, -1.09168714],\n",
              "       [-0.28401079,  0.87525072, -1.37744033, ...,  1.75486502,\n",
              "        -0.57369368, -1.09168714]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAaXUD4FY-2B",
        "outputId": "44f07a3e-fe3c-4ea0-ac2c-7d76812ad6b0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.55204276, -0.36890377,  1.04473698, ...,  1.75486502,\n",
              "        -0.57369368, -1.09168714],\n",
              "       [-1.31490297,  0.10961719, -1.031415  , ..., -0.5698444 ,\n",
              "        -0.57369368, -1.09168714],\n",
              "       [ 0.57162971,  0.30102557,  1.04473698, ..., -0.5698444 ,\n",
              "         1.74309049, -1.09168714],\n",
              "       ...,\n",
              "       [-0.74791227, -0.27319958, -1.37744033, ..., -0.5698444 ,\n",
              "         1.74309049,  0.91601335],\n",
              "       [-0.00566991, -0.46460796, -0.33936434, ...,  1.75486502,\n",
              "        -0.57369368,  0.91601335],\n",
              "       [-0.79945688, -0.84742473,  1.04473698, ...,  1.75486502,\n",
              "        -0.57369368,  0.91601335]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2 - Now let's make the ANN!"
      ],
      "metadata": {
        "id": "uwN3bgie7bvT"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU\n",
        "from tensorflow.keras.layers import Dropout\n"
      ],
      "metadata": {
        "id": "rL_a7vWu7dj1"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialising the ANN\n",
        "classifier = Sequential()"
      ],
      "metadata": {
        "id": "VDJwvrbZ7kj4"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units=11,activation='relu'))"
      ],
      "metadata": {
        "id": "RSZQrU-g7z4N"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units=6,activation='relu'))"
      ],
      "metadata": {
        "id": "byszZMvw8RcQ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units=1,activation='linear'))"
      ],
      "metadata": {
        "id": "Mk2slmAX8XUI"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.compile(optimizer='adam',loss='mse',metrics=['mse','mae'])"
      ],
      "metadata": {
        "id": "F2udThHo8cFt"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_history=classifier.fit(X_train,y_train,validation_split=0.30,batch_size=10,epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qairJAs8fIc",
        "outputId": "6cdf2dff-a873-4076-846e-43794e03f6a1"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "560/560 [==============================] - 4s 5ms/step - loss: 13406387200.0000 - mse: 13406387200.0000 - mae: 100586.9062 - val_loss: 13175619584.0000 - val_mse: 13175619584.0000 - val_mae: 99078.1250\n",
            "Epoch 2/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 13354075136.0000 - mse: 13354075136.0000 - mae: 100328.8672 - val_loss: 13074150400.0000 - val_mse: 13074150400.0000 - val_mae: 98564.1641\n",
            "Epoch 3/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 13183131648.0000 - mse: 13183131648.0000 - mae: 99481.4609 - val_loss: 12832788480.0000 - val_mse: 12832788480.0000 - val_mae: 97351.8828\n",
            "Epoch 4/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 12857486336.0000 - mse: 12857486336.0000 - mae: 97864.3984 - val_loss: 12430949376.0000 - val_mse: 12430949376.0000 - val_mae: 95333.4453\n",
            "Epoch 5/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 12365009920.0000 - mse: 12365009920.0000 - mae: 95431.6094 - val_loss: 11864886272.0000 - val_mse: 11864886272.0000 - val_mae: 92481.5938\n",
            "Epoch 6/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 11712537600.0000 - mse: 11712537600.0000 - mae: 92150.2188 - val_loss: 11150143488.0000 - val_mse: 11150143488.0000 - val_mae: 88903.4922\n",
            "Epoch 7/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 10917075968.0000 - mse: 10917075968.0000 - mae: 88185.3203 - val_loss: 10309051392.0000 - val_mse: 10309052416.0000 - val_mae: 84700.3672\n",
            "Epoch 8/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 10009195520.0000 - mse: 10009195520.0000 - mae: 83666.0938 - val_loss: 9375154176.0000 - val_mse: 9375154176.0000 - val_mae: 80018.0703\n",
            "Epoch 9/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 9025363968.0000 - mse: 9025363968.0000 - mae: 78766.1875 - val_loss: 8392975360.0000 - val_mse: 8392975360.0000 - val_mae: 75097.7656\n",
            "Epoch 10/200\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 8011157504.0000 - mse: 8011157504.0000 - mae: 73675.8828 - val_loss: 7402596352.0000 - val_mse: 7402596352.0000 - val_mae: 70133.1328\n",
            "Epoch 11/200\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 7015570944.0000 - mse: 7015570944.0000 - mae: 68661.5781 - val_loss: 6463547904.0000 - val_mse: 6463547904.0000 - val_mae: 65399.8203\n",
            "Epoch 12/200\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 6089737728.0000 - mse: 6089737728.0000 - mae: 63942.4609 - val_loss: 5615505920.0000 - val_mse: 5615505920.0000 - val_mae: 61168.6797\n",
            "Epoch 13/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 5276712448.0000 - mse: 5276712448.0000 - mae: 59811.3477 - val_loss: 4898827776.0000 - val_mse: 4898827776.0000 - val_mae: 57644.1133\n",
            "Epoch 14/200\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 4613617664.0000 - mse: 4613617664.0000 - mae: 56380.2578 - val_loss: 4347102208.0000 - val_mse: 4347102208.0000 - val_mae: 54959.1172\n",
            "Epoch 15/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 4115721472.0000 - mse: 4115721472.0000 - mae: 53789.2930 - val_loss: 3956002048.0000 - val_mse: 3956002048.0000 - val_mae: 53055.6211\n",
            "Epoch 16/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3775228672.0000 - mse: 3775228672.0000 - mae: 52094.3047 - val_loss: 3708748288.0000 - val_mse: 3708748288.0000 - val_mae: 51888.8906\n",
            "Epoch 17/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3569044480.0000 - mse: 3569044480.0000 - mae: 51022.7656 - val_loss: 3571214592.0000 - val_mse: 3571214592.0000 - val_mae: 51216.3203\n",
            "Epoch 18/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3459890432.0000 - mse: 3459890432.0000 - mae: 50465.3945 - val_loss: 3505999360.0000 - val_mse: 3505999104.0000 - val_mae: 50877.1094\n",
            "Epoch 19/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3405965056.0000 - mse: 3405965056.0000 - mae: 50206.0352 - val_loss: 3475297024.0000 - val_mse: 3475297024.0000 - val_mae: 50709.3672\n",
            "Epoch 20/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3379533056.0000 - mse: 3379533056.0000 - mae: 50081.6875 - val_loss: 3460584192.0000 - val_mse: 3460584192.0000 - val_mae: 50616.0664\n",
            "Epoch 21/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3365560576.0000 - mse: 3365560576.0000 - mae: 50013.3984 - val_loss: 3452242688.0000 - val_mse: 3452242688.0000 - val_mae: 50553.1406\n",
            "Epoch 22/200\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 3357262848.0000 - mse: 3357262848.0000 - mae: 49966.8789 - val_loss: 3445991680.0000 - val_mse: 3445991680.0000 - val_mae: 50503.0781\n",
            "Epoch 23/200\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 3351235328.0000 - mse: 3351235328.0000 - mae: 49936.5547 - val_loss: 3441513216.0000 - val_mse: 3441513216.0000 - val_mae: 50468.0312\n",
            "Epoch 24/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3346838016.0000 - mse: 3346838016.0000 - mae: 49904.1523 - val_loss: 3438459136.0000 - val_mse: 3438458624.0000 - val_mae: 50442.8359\n",
            "Epoch 25/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3343244544.0000 - mse: 3343244544.0000 - mae: 49879.4805 - val_loss: 3435389440.0000 - val_mse: 3435389440.0000 - val_mae: 50419.7461\n",
            "Epoch 26/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3340359168.0000 - mse: 3340359168.0000 - mae: 49858.4180 - val_loss: 3432684032.0000 - val_mse: 3432683520.0000 - val_mae: 50399.7148\n",
            "Epoch 27/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3337693696.0000 - mse: 3337693696.0000 - mae: 49838.4805 - val_loss: 3430890496.0000 - val_mse: 3430890496.0000 - val_mae: 50385.5039\n",
            "Epoch 28/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3335332608.0000 - mse: 3335332608.0000 - mae: 49821.4844 - val_loss: 3429513216.0000 - val_mse: 3429513216.0000 - val_mae: 50374.1367\n",
            "Epoch 29/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3333323776.0000 - mse: 3333323776.0000 - mae: 49809.7070 - val_loss: 3427416064.0000 - val_mse: 3427416064.0000 - val_mae: 50358.8516\n",
            "Epoch 30/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3331625984.0000 - mse: 3331625984.0000 - mae: 49798.7812 - val_loss: 3425923840.0000 - val_mse: 3425923840.0000 - val_mae: 50346.8086\n",
            "Epoch 31/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3329750784.0000 - mse: 3329751296.0000 - mae: 49783.0039 - val_loss: 3424828928.0000 - val_mse: 3424828928.0000 - val_mae: 50339.5039\n",
            "Epoch 32/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3328184064.0000 - mse: 3328184064.0000 - mae: 49778.2188 - val_loss: 3423961088.0000 - val_mse: 3423961088.0000 - val_mae: 50333.6016\n",
            "Epoch 33/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3326700544.0000 - mse: 3326700544.0000 - mae: 49763.5820 - val_loss: 3422759168.0000 - val_mse: 3422759168.0000 - val_mae: 50326.3516\n",
            "Epoch 34/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3325272320.0000 - mse: 3325272320.0000 - mae: 49751.4609 - val_loss: 3422081280.0000 - val_mse: 3422081280.0000 - val_mae: 50322.0078\n",
            "Epoch 35/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3324004608.0000 - mse: 3324004608.0000 - mae: 49745.9102 - val_loss: 3421238784.0000 - val_mse: 3421238784.0000 - val_mae: 50316.1641\n",
            "Epoch 36/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3322616064.0000 - mse: 3322616064.0000 - mae: 49736.0117 - val_loss: 3420315136.0000 - val_mse: 3420315136.0000 - val_mae: 50309.4336\n",
            "Epoch 37/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3321498624.0000 - mse: 3321498624.0000 - mae: 49728.3047 - val_loss: 3419541504.0000 - val_mse: 3419541504.0000 - val_mae: 50304.7500\n",
            "Epoch 38/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3320228352.0000 - mse: 3320228608.0000 - mae: 49719.0117 - val_loss: 3418692096.0000 - val_mse: 3418692096.0000 - val_mae: 50298.8867\n",
            "Epoch 39/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3319272960.0000 - mse: 3319272960.0000 - mae: 49715.2070 - val_loss: 3418221568.0000 - val_mse: 3418221568.0000 - val_mae: 50295.4453\n",
            "Epoch 40/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3318276864.0000 - mse: 3318276864.0000 - mae: 49704.3125 - val_loss: 3416966912.0000 - val_mse: 3416966912.0000 - val_mae: 50287.1406\n",
            "Epoch 41/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3317297920.0000 - mse: 3317297920.0000 - mae: 49697.0859 - val_loss: 3417057792.0000 - val_mse: 3417057792.0000 - val_mae: 50287.2891\n",
            "Epoch 42/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3316193536.0000 - mse: 3316193536.0000 - mae: 49692.8633 - val_loss: 3416061440.0000 - val_mse: 3416061440.0000 - val_mae: 50280.7383\n",
            "Epoch 43/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3315250432.0000 - mse: 3315250432.0000 - mae: 49686.8125 - val_loss: 3415582208.0000 - val_mse: 3415582208.0000 - val_mae: 50277.3711\n",
            "Epoch 44/200\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 3314316544.0000 - mse: 3314316544.0000 - mae: 49681.5898 - val_loss: 3415059968.0000 - val_mse: 3415059968.0000 - val_mae: 50274.1680\n",
            "Epoch 45/200\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 3313552896.0000 - mse: 3313552896.0000 - mae: 49676.1094 - val_loss: 3414248704.0000 - val_mse: 3414248704.0000 - val_mae: 50267.5352\n",
            "Epoch 46/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3312495104.0000 - mse: 3312495104.0000 - mae: 49669.9531 - val_loss: 3413574912.0000 - val_mse: 3413574912.0000 - val_mae: 50262.7461\n",
            "Epoch 47/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3311713024.0000 - mse: 3311713024.0000 - mae: 49665.8359 - val_loss: 3412955904.0000 - val_mse: 3412955904.0000 - val_mae: 50258.9258\n",
            "Epoch 48/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3310809088.0000 - mse: 3310809088.0000 - mae: 49658.6016 - val_loss: 3412625920.0000 - val_mse: 3412625920.0000 - val_mae: 50255.6914\n",
            "Epoch 49/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3309894912.0000 - mse: 3309894912.0000 - mae: 49654.5273 - val_loss: 3412510976.0000 - val_mse: 3412510976.0000 - val_mae: 50255.3594\n",
            "Epoch 50/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3309304320.0000 - mse: 3309304320.0000 - mae: 49649.5703 - val_loss: 3412170752.0000 - val_mse: 3412170752.0000 - val_mae: 50252.9531\n",
            "Epoch 51/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3308482048.0000 - mse: 3308482048.0000 - mae: 49643.6680 - val_loss: 3411883520.0000 - val_mse: 3411883520.0000 - val_mae: 50251.2383\n",
            "Epoch 52/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3307642112.0000 - mse: 3307642368.0000 - mae: 49641.1367 - val_loss: 3411157760.0000 - val_mse: 3411157760.0000 - val_mae: 50247.6367\n",
            "Epoch 53/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3306832640.0000 - mse: 3306832640.0000 - mae: 49633.5312 - val_loss: 3410601728.0000 - val_mse: 3410601728.0000 - val_mae: 50243.7031\n",
            "Epoch 54/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3306126336.0000 - mse: 3306126336.0000 - mae: 49628.8398 - val_loss: 3410314240.0000 - val_mse: 3410314240.0000 - val_mae: 50242.0352\n",
            "Epoch 55/200\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 3305566976.0000 - mse: 3305566976.0000 - mae: 49626.6641 - val_loss: 3409944576.0000 - val_mse: 3409944576.0000 - val_mae: 50238.6484\n",
            "Epoch 56/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3304791040.0000 - mse: 3304791040.0000 - mae: 49620.7148 - val_loss: 3409376000.0000 - val_mse: 3409376000.0000 - val_mae: 50236.1914\n",
            "Epoch 57/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3304066816.0000 - mse: 3304066816.0000 - mae: 49612.1250 - val_loss: 3409268480.0000 - val_mse: 3409268480.0000 - val_mae: 50235.7656\n",
            "Epoch 58/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3303373568.0000 - mse: 3303373568.0000 - mae: 49611.8281 - val_loss: 3409225472.0000 - val_mse: 3409225472.0000 - val_mae: 50236.5352\n",
            "Epoch 59/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3302808320.0000 - mse: 3302808320.0000 - mae: 49608.6562 - val_loss: 3408441856.0000 - val_mse: 3408441856.0000 - val_mae: 50230.1406\n",
            "Epoch 60/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3302065152.0000 - mse: 3302065152.0000 - mae: 49602.1836 - val_loss: 3407901952.0000 - val_mse: 3407902208.0000 - val_mae: 50227.2812\n",
            "Epoch 61/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3301605632.0000 - mse: 3301605632.0000 - mae: 49597.6172 - val_loss: 3407621888.0000 - val_mse: 3407621888.0000 - val_mae: 50225.0430\n",
            "Epoch 62/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3300883456.0000 - mse: 3300883456.0000 - mae: 49595.8359 - val_loss: 3407641856.0000 - val_mse: 3407641856.0000 - val_mae: 50226.1562\n",
            "Epoch 63/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3300262144.0000 - mse: 3300262144.0000 - mae: 49591.9492 - val_loss: 3407622400.0000 - val_mse: 3407622400.0000 - val_mae: 50226.7852\n",
            "Epoch 64/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3299750656.0000 - mse: 3299750656.0000 - mae: 49586.2344 - val_loss: 3407201024.0000 - val_mse: 3407201024.0000 - val_mae: 50223.3984\n",
            "Epoch 65/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3299191552.0000 - mse: 3299191552.0000 - mae: 49582.8672 - val_loss: 3407364608.0000 - val_mse: 3407364608.0000 - val_mae: 50225.0508\n",
            "Epoch 66/200\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 3298713856.0000 - mse: 3298713856.0000 - mae: 49582.9727 - val_loss: 3406322176.0000 - val_mse: 3406322176.0000 - val_mae: 50218.4219\n",
            "Epoch 67/200\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 3298109184.0000 - mse: 3298109184.0000 - mae: 49576.9531 - val_loss: 3405871104.0000 - val_mse: 3405871104.0000 - val_mae: 50214.5117\n",
            "Epoch 68/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3297547520.0000 - mse: 3297547520.0000 - mae: 49569.9609 - val_loss: 3406348800.0000 - val_mse: 3406348800.0000 - val_mae: 50218.4922\n",
            "Epoch 69/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3297403136.0000 - mse: 3297403136.0000 - mae: 49571.1875 - val_loss: 3405912832.0000 - val_mse: 3405912576.0000 - val_mae: 50215.8594\n",
            "Epoch 70/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3296462336.0000 - mse: 3296462336.0000 - mae: 49567.3125 - val_loss: 3405765376.0000 - val_mse: 3405765376.0000 - val_mae: 50214.0938\n",
            "Epoch 71/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3296056832.0000 - mse: 3296056832.0000 - mae: 49563.5781 - val_loss: 3405740800.0000 - val_mse: 3405740800.0000 - val_mae: 50213.7891\n",
            "Epoch 72/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3295734272.0000 - mse: 3295734272.0000 - mae: 49560.8984 - val_loss: 3405969152.0000 - val_mse: 3405969152.0000 - val_mae: 50216.3281\n",
            "Epoch 73/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3295091712.0000 - mse: 3295091712.0000 - mae: 49559.4297 - val_loss: 3404887552.0000 - val_mse: 3404887552.0000 - val_mae: 50208.4453\n",
            "Epoch 74/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3294724352.0000 - mse: 3294724352.0000 - mae: 49553.9883 - val_loss: 3404295680.0000 - val_mse: 3404295680.0000 - val_mae: 50204.5391\n",
            "Epoch 75/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3294348288.0000 - mse: 3294348288.0000 - mae: 49555.0156 - val_loss: 3404122112.0000 - val_mse: 3404122112.0000 - val_mae: 50203.6641\n",
            "Epoch 76/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3293875200.0000 - mse: 3293875200.0000 - mae: 49551.7305 - val_loss: 3403845632.0000 - val_mse: 3403845632.0000 - val_mae: 50201.6367\n",
            "Epoch 77/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3293334528.0000 - mse: 3293334528.0000 - mae: 49544.3047 - val_loss: 3404115200.0000 - val_mse: 3404115200.0000 - val_mae: 50203.8281\n",
            "Epoch 78/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3292913152.0000 - mse: 3292913152.0000 - mae: 49544.4453 - val_loss: 3403883776.0000 - val_mse: 3403883776.0000 - val_mae: 50202.3672\n",
            "Epoch 79/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3292587520.0000 - mse: 3292587520.0000 - mae: 49544.2734 - val_loss: 3403243008.0000 - val_mse: 3403243008.0000 - val_mae: 50197.2969\n",
            "Epoch 80/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3292513280.0000 - mse: 3292513280.0000 - mae: 49539.6797 - val_loss: 3403268608.0000 - val_mse: 3403268608.0000 - val_mae: 50198.5117\n",
            "Epoch 81/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3291959040.0000 - mse: 3291959040.0000 - mae: 49535.4922 - val_loss: 3403198208.0000 - val_mse: 3403198208.0000 - val_mae: 50199.4883\n",
            "Epoch 82/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3291450368.0000 - mse: 3291450368.0000 - mae: 49535.4219 - val_loss: 3402892800.0000 - val_mse: 3402892800.0000 - val_mae: 50196.7109\n",
            "Epoch 83/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3291086592.0000 - mse: 3291086592.0000 - mae: 49532.5898 - val_loss: 3402988288.0000 - val_mse: 3402988288.0000 - val_mae: 50197.9414\n",
            "Epoch 84/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3290739712.0000 - mse: 3290739712.0000 - mae: 49530.0352 - val_loss: 3403045888.0000 - val_mse: 3403045888.0000 - val_mae: 50197.6484\n",
            "Epoch 85/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3290515712.0000 - mse: 3290515712.0000 - mae: 49529.6172 - val_loss: 3403101440.0000 - val_mse: 3403101440.0000 - val_mae: 50198.7383\n",
            "Epoch 86/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3290082816.0000 - mse: 3290082816.0000 - mae: 49525.1641 - val_loss: 3402902528.0000 - val_mse: 3402902528.0000 - val_mae: 50197.6406\n",
            "Epoch 87/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3289696000.0000 - mse: 3289696000.0000 - mae: 49522.5586 - val_loss: 3403307520.0000 - val_mse: 3403307520.0000 - val_mae: 50201.6641\n",
            "Epoch 88/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3289586688.0000 - mse: 3289586688.0000 - mae: 49523.3828 - val_loss: 3402735872.0000 - val_mse: 3402735872.0000 - val_mae: 50197.0312\n",
            "Epoch 89/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3289019648.0000 - mse: 3289019648.0000 - mae: 49519.1211 - val_loss: 3402847744.0000 - val_mse: 3402847744.0000 - val_mae: 50199.2344\n",
            "Epoch 90/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3288886784.0000 - mse: 3288886784.0000 - mae: 49517.7266 - val_loss: 3402528256.0000 - val_mse: 3402528256.0000 - val_mae: 50197.0469\n",
            "Epoch 91/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3288416256.0000 - mse: 3288416256.0000 - mae: 49516.6523 - val_loss: 3402499840.0000 - val_mse: 3402499840.0000 - val_mae: 50197.0625\n",
            "Epoch 92/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3288394240.0000 - mse: 3288394240.0000 - mae: 49512.0273 - val_loss: 3402503680.0000 - val_mse: 3402503680.0000 - val_mae: 50196.6602\n",
            "Epoch 93/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3287781120.0000 - mse: 3287781120.0000 - mae: 49512.2227 - val_loss: 3402253824.0000 - val_mse: 3402253824.0000 - val_mae: 50195.5859\n",
            "Epoch 94/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3287638272.0000 - mse: 3287638272.0000 - mae: 49506.7891 - val_loss: 3401898496.0000 - val_mse: 3401898496.0000 - val_mae: 50191.9648\n",
            "Epoch 95/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3287418368.0000 - mse: 3287418368.0000 - mae: 49505.3320 - val_loss: 3401695232.0000 - val_mse: 3401695232.0000 - val_mae: 50190.8359\n",
            "Epoch 96/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3287014144.0000 - mse: 3287014144.0000 - mae: 49505.5391 - val_loss: 3401708800.0000 - val_mse: 3401708800.0000 - val_mae: 50192.0586\n",
            "Epoch 97/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3286720256.0000 - mse: 3286720256.0000 - mae: 49502.5273 - val_loss: 3402000128.0000 - val_mse: 3402000128.0000 - val_mae: 50194.7227\n",
            "Epoch 98/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3286439424.0000 - mse: 3286439424.0000 - mae: 49501.8750 - val_loss: 3402053632.0000 - val_mse: 3402053632.0000 - val_mae: 50196.1016\n",
            "Epoch 99/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3286236928.0000 - mse: 3286236928.0000 - mae: 49500.2109 - val_loss: 3402021888.0000 - val_mse: 3402021888.0000 - val_mae: 50194.6680\n",
            "Epoch 100/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3285813760.0000 - mse: 3285813760.0000 - mae: 49496.0859 - val_loss: 3402338048.0000 - val_mse: 3402338048.0000 - val_mae: 50198.2969\n",
            "Epoch 101/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3285588480.0000 - mse: 3285588480.0000 - mae: 49494.1875 - val_loss: 3402207744.0000 - val_mse: 3402207744.0000 - val_mae: 50197.8477\n",
            "Epoch 102/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3285551616.0000 - mse: 3285551616.0000 - mae: 49496.2383 - val_loss: 3401833728.0000 - val_mse: 3401833728.0000 - val_mae: 50195.2031\n",
            "Epoch 103/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3285172992.0000 - mse: 3285172992.0000 - mae: 49491.1094 - val_loss: 3401631488.0000 - val_mse: 3401631488.0000 - val_mae: 50192.9883\n",
            "Epoch 104/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3285046784.0000 - mse: 3285046784.0000 - mae: 49491.0703 - val_loss: 3401676288.0000 - val_mse: 3401676288.0000 - val_mae: 50195.1719\n",
            "Epoch 105/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3284791296.0000 - mse: 3284791296.0000 - mae: 49484.2109 - val_loss: 3401454592.0000 - val_mse: 3401454592.0000 - val_mae: 50192.9648\n",
            "Epoch 106/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3284520192.0000 - mse: 3284520192.0000 - mae: 49484.4805 - val_loss: 3401335552.0000 - val_mse: 3401335552.0000 - val_mae: 50193.1172\n",
            "Epoch 107/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3284151296.0000 - mse: 3284151296.0000 - mae: 49482.9766 - val_loss: 3401587200.0000 - val_mse: 3401587200.0000 - val_mae: 50195.0664\n",
            "Epoch 108/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3283965184.0000 - mse: 3283965184.0000 - mae: 49483.7383 - val_loss: 3401794560.0000 - val_mse: 3401794560.0000 - val_mae: 50196.5391\n",
            "Epoch 109/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3283655424.0000 - mse: 3283655424.0000 - mae: 49479.4180 - val_loss: 3401896960.0000 - val_mse: 3401896960.0000 - val_mae: 50197.6680\n",
            "Epoch 110/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3283428608.0000 - mse: 3283428608.0000 - mae: 49476.7188 - val_loss: 3401523968.0000 - val_mse: 3401523968.0000 - val_mae: 50195.3203\n",
            "Epoch 111/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3283543552.0000 - mse: 3283543552.0000 - mae: 49476.4570 - val_loss: 3401814272.0000 - val_mse: 3401814272.0000 - val_mae: 50197.4609\n",
            "Epoch 112/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3283064576.0000 - mse: 3283064576.0000 - mae: 49473.8555 - val_loss: 3401177088.0000 - val_mse: 3401177088.0000 - val_mae: 50192.6250\n",
            "Epoch 113/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3282901504.0000 - mse: 3282901504.0000 - mae: 49474.6211 - val_loss: 3401157632.0000 - val_mse: 3401157376.0000 - val_mae: 50191.8516\n",
            "Epoch 114/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3282686208.0000 - mse: 3282686208.0000 - mae: 49472.4453 - val_loss: 3401183232.0000 - val_mse: 3401183232.0000 - val_mae: 50192.2383\n",
            "Epoch 115/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3282506752.0000 - mse: 3282506752.0000 - mae: 49470.7266 - val_loss: 3400965888.0000 - val_mse: 3400965888.0000 - val_mae: 50191.0586\n",
            "Epoch 116/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3282396416.0000 - mse: 3282396416.0000 - mae: 49471.6211 - val_loss: 3401123072.0000 - val_mse: 3401123072.0000 - val_mae: 50193.1797\n",
            "Epoch 117/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3282199296.0000 - mse: 3282199296.0000 - mae: 49470.1328 - val_loss: 3400908288.0000 - val_mse: 3400908032.0000 - val_mae: 50190.6562\n",
            "Epoch 118/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3282023680.0000 - mse: 3282023680.0000 - mae: 49466.3203 - val_loss: 3400768256.0000 - val_mse: 3400768256.0000 - val_mae: 50191.3828\n",
            "Epoch 119/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3281709312.0000 - mse: 3281709312.0000 - mae: 49464.3438 - val_loss: 3400952832.0000 - val_mse: 3400952832.0000 - val_mae: 50192.2617\n",
            "Epoch 120/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3281573376.0000 - mse: 3281573376.0000 - mae: 49465.5273 - val_loss: 3401040896.0000 - val_mse: 3401040896.0000 - val_mae: 50192.6250\n",
            "Epoch 121/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3281270016.0000 - mse: 3281270016.0000 - mae: 49465.8633 - val_loss: 3401051392.0000 - val_mse: 3401051392.0000 - val_mae: 50192.6055\n",
            "Epoch 122/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3281127168.0000 - mse: 3281127168.0000 - mae: 49458.2188 - val_loss: 3401143808.0000 - val_mse: 3401143808.0000 - val_mae: 50194.8750\n",
            "Epoch 123/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3280926464.0000 - mse: 3280926464.0000 - mae: 49462.2305 - val_loss: 3400767232.0000 - val_mse: 3400767232.0000 - val_mae: 50192.2461\n",
            "Epoch 124/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3280791296.0000 - mse: 3280791296.0000 - mae: 49460.4297 - val_loss: 3400901632.0000 - val_mse: 3400901632.0000 - val_mae: 50192.6016\n",
            "Epoch 125/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3280566528.0000 - mse: 3280566528.0000 - mae: 49456.7266 - val_loss: 3400896768.0000 - val_mse: 3400896768.0000 - val_mae: 50193.5859\n",
            "Epoch 126/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3280493312.0000 - mse: 3280493312.0000 - mae: 49457.5156 - val_loss: 3401181696.0000 - val_mse: 3401181696.0000 - val_mae: 50195.1680\n",
            "Epoch 127/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3280089088.0000 - mse: 3280089088.0000 - mae: 49457.2578 - val_loss: 3401024768.0000 - val_mse: 3401025024.0000 - val_mae: 50194.7031\n",
            "Epoch 128/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3279842048.0000 - mse: 3279842048.0000 - mae: 49450.3672 - val_loss: 3401719040.0000 - val_mse: 3401719040.0000 - val_mae: 50200.6406\n",
            "Epoch 129/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3279889920.0000 - mse: 3279889920.0000 - mae: 49453.6797 - val_loss: 3401255424.0000 - val_mse: 3401255424.0000 - val_mae: 50198.1797\n",
            "Epoch 130/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3279643136.0000 - mse: 3279643136.0000 - mae: 49448.8867 - val_loss: 3400994048.0000 - val_mse: 3400994048.0000 - val_mae: 50195.8789\n",
            "Epoch 131/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3279523584.0000 - mse: 3279523584.0000 - mae: 49449.7188 - val_loss: 3401491200.0000 - val_mse: 3401491200.0000 - val_mae: 50200.4141\n",
            "Epoch 132/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3279203840.0000 - mse: 3279203840.0000 - mae: 49450.5469 - val_loss: 3401204480.0000 - val_mse: 3401204480.0000 - val_mae: 50198.5039\n",
            "Epoch 133/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3279079168.0000 - mse: 3279079168.0000 - mae: 49444.7930 - val_loss: 3401515776.0000 - val_mse: 3401515776.0000 - val_mae: 50200.9648\n",
            "Epoch 134/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3279038976.0000 - mse: 3279038976.0000 - mae: 49448.3359 - val_loss: 3401636096.0000 - val_mse: 3401636096.0000 - val_mae: 50201.8281\n",
            "Epoch 135/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3278885888.0000 - mse: 3278885888.0000 - mae: 49445.4922 - val_loss: 3401441024.0000 - val_mse: 3401441024.0000 - val_mae: 50201.3984\n",
            "Epoch 136/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3278642176.0000 - mse: 3278642176.0000 - mae: 49444.8398 - val_loss: 3401181440.0000 - val_mse: 3401181440.0000 - val_mae: 50198.4102\n",
            "Epoch 137/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3278687488.0000 - mse: 3278687488.0000 - mae: 49445.1445 - val_loss: 3401473792.0000 - val_mse: 3401473792.0000 - val_mae: 50201.8516\n",
            "Epoch 138/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3278312960.0000 - mse: 3278312960.0000 - mae: 49440.7383 - val_loss: 3401010432.0000 - val_mse: 3401010432.0000 - val_mae: 50197.4883\n",
            "Epoch 139/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3278040064.0000 - mse: 3278040064.0000 - mae: 49441.2617 - val_loss: 3400782848.0000 - val_mse: 3400782848.0000 - val_mae: 50196.9961\n",
            "Epoch 140/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3277913088.0000 - mse: 3277913088.0000 - mae: 49439.7070 - val_loss: 3401143296.0000 - val_mse: 3401143296.0000 - val_mae: 50199.1094\n",
            "Epoch 141/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3277851136.0000 - mse: 3277851136.0000 - mae: 49438.3594 - val_loss: 3400924672.0000 - val_mse: 3400924672.0000 - val_mae: 50197.8320\n",
            "Epoch 142/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3277859072.0000 - mse: 3277859072.0000 - mae: 49439.8359 - val_loss: 3401193984.0000 - val_mse: 3401193984.0000 - val_mae: 50200.4258\n",
            "Epoch 143/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3277363712.0000 - mse: 3277363712.0000 - mae: 49436.0781 - val_loss: 3401049600.0000 - val_mse: 3401049600.0000 - val_mae: 50199.7266\n",
            "Epoch 144/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3277299200.0000 - mse: 3277299200.0000 - mae: 49436.3672 - val_loss: 3400602624.0000 - val_mse: 3400602624.0000 - val_mae: 50196.4258\n",
            "Epoch 145/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3277051392.0000 - mse: 3277051392.0000 - mae: 49430.3086 - val_loss: 3401243136.0000 - val_mse: 3401243136.0000 - val_mae: 50201.3359\n",
            "Epoch 146/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3277016576.0000 - mse: 3277016576.0000 - mae: 49435.3047 - val_loss: 3400968704.0000 - val_mse: 3400968704.0000 - val_mae: 50200.7031\n",
            "Epoch 147/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3276785408.0000 - mse: 3276785408.0000 - mae: 49432.4961 - val_loss: 3401030912.0000 - val_mse: 3401030912.0000 - val_mae: 50200.8281\n",
            "Epoch 148/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3276645632.0000 - mse: 3276645632.0000 - mae: 49434.6445 - val_loss: 3401294080.0000 - val_mse: 3401294080.0000 - val_mae: 50203.0781\n",
            "Epoch 149/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3276439808.0000 - mse: 3276439808.0000 - mae: 49429.0742 - val_loss: 3401090816.0000 - val_mse: 3401090816.0000 - val_mae: 50201.4141\n",
            "Epoch 150/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3276357632.0000 - mse: 3276357632.0000 - mae: 49432.5547 - val_loss: 3401295360.0000 - val_mse: 3401295360.0000 - val_mae: 50203.5352\n",
            "Epoch 151/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3276187648.0000 - mse: 3276187648.0000 - mae: 49429.9375 - val_loss: 3401074944.0000 - val_mse: 3401074944.0000 - val_mae: 50202.1211\n",
            "Epoch 152/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3276110080.0000 - mse: 3276110592.0000 - mae: 49429.1367 - val_loss: 3401374464.0000 - val_mse: 3401374464.0000 - val_mae: 50204.3125\n",
            "Epoch 153/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3275936768.0000 - mse: 3275936768.0000 - mae: 49426.5273 - val_loss: 3401287424.0000 - val_mse: 3401287424.0000 - val_mae: 50203.1875\n",
            "Epoch 154/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3275587328.0000 - mse: 3275587328.0000 - mae: 49424.2578 - val_loss: 3401774592.0000 - val_mse: 3401774592.0000 - val_mae: 50207.2383\n",
            "Epoch 155/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3275617792.0000 - mse: 3275617792.0000 - mae: 49424.7148 - val_loss: 3401707776.0000 - val_mse: 3401707776.0000 - val_mae: 50207.4805\n",
            "Epoch 156/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3275341312.0000 - mse: 3275341312.0000 - mae: 49421.9648 - val_loss: 3401924608.0000 - val_mse: 3401924608.0000 - val_mae: 50208.3008\n",
            "Epoch 157/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3275153664.0000 - mse: 3275153664.0000 - mae: 49420.7266 - val_loss: 3402015744.0000 - val_mse: 3402015744.0000 - val_mae: 50209.7227\n",
            "Epoch 158/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3275060736.0000 - mse: 3275061504.0000 - mae: 49420.9766 - val_loss: 3401882112.0000 - val_mse: 3401882112.0000 - val_mae: 50208.3008\n",
            "Epoch 159/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3274898688.0000 - mse: 3274898688.0000 - mae: 49419.6914 - val_loss: 3402102272.0000 - val_mse: 3402102272.0000 - val_mae: 50210.4492\n",
            "Epoch 160/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3274913792.0000 - mse: 3274913792.0000 - mae: 49419.0391 - val_loss: 3402272512.0000 - val_mse: 3402272512.0000 - val_mae: 50212.2109\n",
            "Epoch 161/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3274701824.0000 - mse: 3274701824.0000 - mae: 49419.7383 - val_loss: 3402182400.0000 - val_mse: 3402182400.0000 - val_mae: 50211.2227\n",
            "Epoch 162/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3274456064.0000 - mse: 3274456064.0000 - mae: 49416.2734 - val_loss: 3402229760.0000 - val_mse: 3402229760.0000 - val_mae: 50211.5586\n",
            "Epoch 163/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3274374400.0000 - mse: 3274374400.0000 - mae: 49416.2852 - val_loss: 3402268160.0000 - val_mse: 3402268160.0000 - val_mae: 50212.8906\n",
            "Epoch 164/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3274277888.0000 - mse: 3274277888.0000 - mae: 49413.6875 - val_loss: 3402039552.0000 - val_mse: 3402039552.0000 - val_mae: 50211.2617\n",
            "Epoch 165/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3274030592.0000 - mse: 3274030592.0000 - mae: 49413.4922 - val_loss: 3402322432.0000 - val_mse: 3402322432.0000 - val_mae: 50213.2656\n",
            "Epoch 166/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3273978624.0000 - mse: 3273978624.0000 - mae: 49410.3086 - val_loss: 3402607616.0000 - val_mse: 3402607616.0000 - val_mae: 50214.5625\n",
            "Epoch 167/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3273931520.0000 - mse: 3273931520.0000 - mae: 49410.7891 - val_loss: 3402166528.0000 - val_mse: 3402166528.0000 - val_mae: 50211.8594\n",
            "Epoch 168/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3273692416.0000 - mse: 3273692416.0000 - mae: 49409.3359 - val_loss: 3402516224.0000 - val_mse: 3402516224.0000 - val_mae: 50215.5703\n",
            "Epoch 169/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3273462784.0000 - mse: 3273462784.0000 - mae: 49409.8516 - val_loss: 3402290432.0000 - val_mse: 3402290432.0000 - val_mae: 50213.8242\n",
            "Epoch 170/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3273378560.0000 - mse: 3273378560.0000 - mae: 49410.2500 - val_loss: 3402689024.0000 - val_mse: 3402688768.0000 - val_mae: 50216.9570\n",
            "Epoch 171/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3273200640.0000 - mse: 3273200640.0000 - mae: 49408.0273 - val_loss: 3402121728.0000 - val_mse: 3402121728.0000 - val_mae: 50212.1367\n",
            "Epoch 172/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3273115648.0000 - mse: 3273115648.0000 - mae: 49402.8398 - val_loss: 3402196480.0000 - val_mse: 3402196736.0000 - val_mae: 50212.7031\n",
            "Epoch 173/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3272894720.0000 - mse: 3272894720.0000 - mae: 49399.8125 - val_loss: 3402263040.0000 - val_mse: 3402263040.0000 - val_mae: 50213.4375\n",
            "Epoch 174/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3272747264.0000 - mse: 3272747264.0000 - mae: 49401.1211 - val_loss: 3402598656.0000 - val_mse: 3402598656.0000 - val_mae: 50215.8672\n",
            "Epoch 175/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3272816896.0000 - mse: 3272816896.0000 - mae: 49401.5898 - val_loss: 3401912064.0000 - val_mse: 3401912064.0000 - val_mae: 50210.6523\n",
            "Epoch 176/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3272388864.0000 - mse: 3272388864.0000 - mae: 49399.9297 - val_loss: 3402411264.0000 - val_mse: 3402411264.0000 - val_mae: 50215.0625\n",
            "Epoch 177/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3272413696.0000 - mse: 3272413696.0000 - mae: 49400.9297 - val_loss: 3402023680.0000 - val_mse: 3402023680.0000 - val_mae: 50211.1758\n",
            "Epoch 178/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3272156416.0000 - mse: 3272156416.0000 - mae: 49394.5391 - val_loss: 3402844416.0000 - val_mse: 3402844416.0000 - val_mae: 50217.5352\n",
            "Epoch 179/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3272100096.0000 - mse: 3272100096.0000 - mae: 49395.9141 - val_loss: 3402545152.0000 - val_mse: 3402545152.0000 - val_mae: 50215.6719\n",
            "Epoch 180/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3271958272.0000 - mse: 3271958272.0000 - mae: 49395.5195 - val_loss: 3402560768.0000 - val_mse: 3402560768.0000 - val_mae: 50215.3633\n",
            "Epoch 181/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3271947008.0000 - mse: 3271947008.0000 - mae: 49396.8359 - val_loss: 3402662656.0000 - val_mse: 3402662656.0000 - val_mae: 50214.8828\n",
            "Epoch 182/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3271802112.0000 - mse: 3271802112.0000 - mae: 49392.7148 - val_loss: 3402468608.0000 - val_mse: 3402468608.0000 - val_mae: 50213.9336\n",
            "Epoch 183/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3271643904.0000 - mse: 3271643904.0000 - mae: 49395.5430 - val_loss: 3402626816.0000 - val_mse: 3402626816.0000 - val_mae: 50216.1055\n",
            "Epoch 184/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3271513600.0000 - mse: 3271513600.0000 - mae: 49395.6445 - val_loss: 3402148096.0000 - val_mse: 3402148096.0000 - val_mae: 50212.0117\n",
            "Epoch 185/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3271331584.0000 - mse: 3271331584.0000 - mae: 49392.0039 - val_loss: 3402591232.0000 - val_mse: 3402591232.0000 - val_mae: 50214.4883\n",
            "Epoch 186/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3271361280.0000 - mse: 3271361280.0000 - mae: 49390.0703 - val_loss: 3402891520.0000 - val_mse: 3402891520.0000 - val_mae: 50217.0547\n",
            "Epoch 187/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3271032064.0000 - mse: 3271032064.0000 - mae: 49388.9531 - val_loss: 3403161600.0000 - val_mse: 3403161600.0000 - val_mae: 50218.9375\n",
            "Epoch 188/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3271067392.0000 - mse: 3271067392.0000 - mae: 49392.7891 - val_loss: 3402990336.0000 - val_mse: 3402990336.0000 - val_mae: 50218.8281\n",
            "Epoch 189/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3270913280.0000 - mse: 3270913280.0000 - mae: 49386.2969 - val_loss: 3403115264.0000 - val_mse: 3403115264.0000 - val_mae: 50219.8984\n",
            "Epoch 190/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3270877696.0000 - mse: 3270877696.0000 - mae: 49387.9531 - val_loss: 3403023360.0000 - val_mse: 3403023360.0000 - val_mae: 50218.3320\n",
            "Epoch 191/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3270592000.0000 - mse: 3270592000.0000 - mae: 49385.4531 - val_loss: 3402913536.0000 - val_mse: 3402913536.0000 - val_mae: 50217.3906\n",
            "Epoch 192/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3270565376.0000 - mse: 3270565376.0000 - mae: 49383.6680 - val_loss: 3402760960.0000 - val_mse: 3402760960.0000 - val_mae: 50216.3438\n",
            "Epoch 193/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3270372608.0000 - mse: 3270372608.0000 - mae: 49381.4570 - val_loss: 3403127296.0000 - val_mse: 3403127296.0000 - val_mae: 50219.0586\n",
            "Epoch 194/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3270236416.0000 - mse: 3270236416.0000 - mae: 49379.5312 - val_loss: 3402945536.0000 - val_mse: 3402945536.0000 - val_mae: 50218.1914\n",
            "Epoch 195/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3270212352.0000 - mse: 3270212352.0000 - mae: 49381.4961 - val_loss: 3402701312.0000 - val_mse: 3402701312.0000 - val_mae: 50216.1719\n",
            "Epoch 196/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3270044160.0000 - mse: 3270044160.0000 - mae: 49377.6797 - val_loss: 3403176704.0000 - val_mse: 3403176704.0000 - val_mae: 50220.1055\n",
            "Epoch 197/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3269980416.0000 - mse: 3269980416.0000 - mae: 49379.0781 - val_loss: 3403129856.0000 - val_mse: 3403129856.0000 - val_mae: 50219.5273\n",
            "Epoch 198/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3269739264.0000 - mse: 3269739264.0000 - mae: 49378.1758 - val_loss: 3403229440.0000 - val_mse: 3403229440.0000 - val_mae: 50220.3867\n",
            "Epoch 199/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3269785856.0000 - mse: 3269785856.0000 - mae: 49377.3203 - val_loss: 3403255552.0000 - val_mse: 3403255552.0000 - val_mae: 50221.0078\n",
            "Epoch 200/200\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 3269675264.0000 - mse: 3269675264.0000 - mae: 49373.0000 - val_loss: 3402977280.0000 - val_mse: 3402977024.0000 - val_mae: 50219.4883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "\n",
        "print(model_history.history.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9t_M4wICTTz",
        "outputId": "0c69e2e6-49ae-4ced-8aae-a1d69279fcc3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'mse', 'mae', 'val_loss', 'val_mse', 'val_mae'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(model_history.history['mae'])\n",
        "plt.plot(model_history.history['val_mae'])\n",
        "plt.title('model mae')\n",
        "plt.ylabel('mae')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "MMOyiwzgBlLY",
        "outputId": "4c23f66a-56d1-4941-a781-4f0ec8669e68"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "plt.plot(model_history.history['loss'])\n",
        "plt.plot(model_history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "QH141RsQCEr0",
        "outputId": "a2de4e99-9468-41ab-b0fc-2b2e48fbc915"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 3 - Making the predictions and evaluating the model\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "# y_pred = (y_pred > 0.5)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "OYqCIIkDCd8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88364af4-18b6-4358-a8ea-f605708d1178"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[105147.66 ],\n",
              "       [102828.15 ],\n",
              "       [103562.22 ],\n",
              "       ...,\n",
              "       [ 95113.805],\n",
              "       [103375.79 ],\n",
              "       [107879.695]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "cm3EeOGTCi3-",
        "outputId": "820de074-a8c2-4807-99ca-6497fa735779"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-d6b90b5d4385>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Making the Confusion Matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: continuous is not supported"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "score=accuracy_score(y_pred,y_test)"
      ],
      "metadata": {
        "id": "FgfRKzzOClmP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "723c4fa0-b065-43ac-9031-1d2ffb08623a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-53d4e3a2d018>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculate the Accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: continuous is not supported"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_C5EETrCpSj",
        "outputId": "e32fc024-9aa0-414e-ce9e-9c36d61be77e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.846"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UTvHAjYWCqWx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}